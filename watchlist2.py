import csv
import requests
import re
import sys
import time
from bs4 import BeautifulSoup
from app.login import login_and_get_cookies, create_session_with_cookies

# ğŸ”¹ ZÃ¡kladnÃ© nastavenia
WATCHLIST_URL = "https://www.csfd.cz/soukrome/chci-videt/?filmType=1"  #?filmType=0
HEADERS = {"User-Agent": "Mozilla/5.0"}

# ğŸ”¹ 1ï¸âƒ£ Stiahni zoznam filmov z "Chci vidÄ›t"
def get_watchlist(session):
    movies = []
    page = 1
    previous_titles = []

    while True:
        url = f"{WATCHLIST_URL}&page={page}"
        print(url)
        response = session.get(url, headers=HEADERS)
        time.sleep(0.5)  # Prevencia proti rate-limitingu

        if response.status_code != 200:
            print("âŒ Chyba pri naÄÃ­tanÃ­ strÃ¡nky!")
            return []

        soup = BeautifulSoup(response.text, "html.parser")
        movie_rows = soup.select("h3.film-title-nooverflow a.film-title-name")

        if not movie_rows:
            break  # Ak uÅ¾ nie sÃº ÄalÅ¡ie filmy, ukonÄi
        
        current_titles = [row.text.strip() for row in movie_rows]

        # Ak sa nÃ¡zvy filmov na strÃ¡nke nezmenili, znamenÃ¡ to, Å¾e sme na poslednej strÃ¡nke
        if current_titles == previous_titles:
            break

        print(f"ğŸ”„ SpracovÃ¡vam strÃ¡nku {page}...")
        for row in movie_rows:
            title = row.text.strip()
            link = "https://www.csfd.cz" + row["href"]

            # ZÃ­skaÅ¥ rok vzniku filmu
            year_tag = row.find_next("span", class_="film-title-info")
            year = re.search(r"\d{4}", year_tag.text).group(0) if year_tag else "N/A"

            movies.append({
                "title": title, 
                "englishTitle": "",
                "year": year, 
                "link": link, 
                "totalRatings": 0,
                "genres": "",
                "plot": ""
            })

        # UloÅ¾Ã­me nÃ¡zvy filmov z tejto strÃ¡nky pre porovnanie na ÄalÅ¡iu strÃ¡nku
        previous_titles = current_titles

        page += 1  # Posun na ÄalÅ¡iu strÃ¡nku

    return movies

# ğŸ”¹ 2ï¸âƒ£ ZÃ­skaÅ¥ detailnÃ© informÃ¡cie o filme (hodnotenia, Å¾Ã¡nre, anglickÃ½ nÃ¡zov, obsah)
def get_movie_details(movie_url, current_index, total_movies):
    retries = 3
    while retries > 0:
        response = requests.get(movie_url, headers=HEADERS, timeout=10)
        time.sleep(0.1)  # Prevent rate limiting

        if response.status_code != 200:
            print(f"âŒ Chyba pri naÄÃ­tanÃ­ strÃ¡nky: {movie_url}")
            retries -= 1
            time.sleep(2)
            continue

        soup = BeautifulSoup(response.text, "html.parser")
        
        # ZÃ­skaÅ¥ poÄet hodnotenÃ­
        rating_count = 0
        rating_count_tag = soup.select_one("li.tab-nav-item.ratings-btn.active span.counter")
        if rating_count_tag:
            rating_count_text = rating_count_tag.text.strip()
            rating_count = int(re.sub(r"\D", "", rating_count_text))

        # ZÃ­skaÅ¥ anglickÃ½ nÃ¡zov
        english_title = ""
        english_title_tag = soup.select_one("ul.names li[title]")
        if english_title_tag:
            english_title = english_title_tag.text.strip()
        
        # ZÃ­skaÅ¥ Å¾Ã¡nre
        genres = []
        genres_div = soup.select_one("div.genres")
        if genres_div:
            genre_links = genres_div.select("a")
            genres = [genre.text.strip() for genre in genre_links]
        genres_str = " / ".join(genres) if genres else ""
        
        # ZÃ­skaÅ¥ obsah/popis
        plot = ""
        plot_div = soup.select_one("div.plot-full")
        if plot_div:
            # ZÃ­skaÅ¥ text a odstrÃ¡niÅ¥ nadbytoÄnÃ© medzery
            plot_text = plot_div.get_text(separator=" ", strip=True)
            # VyÄistiÅ¥ text od viacerÃ½ch medzier
            plot = re.sub(r'\s+', ' ', plot_text).strip()

        # PrekreslÃ­me riadok s aktuÃ¡lnym poÄÃ­tadlom
        sys.stdout.write(f"\rZpracovÃ¡no: {current_index + 1} / {total_movies} filmÅ¯.")
        sys.stdout.flush()
        
        return {
            "totalRatings": rating_count,
            "englishTitle": english_title,
            "genres": genres_str,
            "plot": plot
        }
    
    return {
        "totalRatings": 0,
        "englishTitle": "",
        "genres": "",
        "plot": ""
    }

# ğŸ”¹ 3ï¸âƒ£ UloÅ¾enie dÃ¡t do CSV (bez filmov s 0 hodnoteniami)
def save_to_csv(movies, filename="watchlist_sorted.csv"):
    # OdstrÃ¡niÅ¥ filmy s 0 hodnoteniami
    filtered_movies = [movie for movie in movies if movie["totalRatings"] > 0]
    # OdstrÃ¡niÅ¥ "link" zo vÅ¡etkÃ½ch slovnÃ­kov
    for movie in filtered_movies:
        movie.pop("link", None)  # BezpeÄne odstrÃ¡ni kÄ¾ÃºÄ, ak existuje

    with open(filename, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.DictWriter(file, fieldnames=["title", "englishTitle", "year", "totalRatings", "genres", "plot"])
        writer.writeheader()
        writer.writerows(filtered_movies)

    print(f"\nâœ… DÃ¡ta boli uloÅ¾enÃ© do {filename} (poÄet filmov: {len(filtered_movies)})")

# ğŸ”¹ 4ï¸âƒ£ HlavnÃ¡ funkcia
def main():
    cookies = login_and_get_cookies()
    if cookies:
        session = create_session_with_cookies(cookies)
        watchlist = get_watchlist(session)

        total_movies = len(watchlist)  
        # PoÄet filmov na spracovanie
        for index, movie in enumerate(watchlist):
            details = get_movie_details(movie["link"], index, total_movies)
            movie["totalRatings"] = details["totalRatings"]
            movie["englishTitle"] = details["englishTitle"]
            movie["genres"] = details["genres"]
            movie["plot"] = details["plot"]

        # ZoradiÅ¥ filmy podÄ¾a poÄtu hodnotenÃ­ (od najviac hodnotenÃ½ch)
        watchlist_sorted = sorted(watchlist, key=lambda x: x["totalRatings"], reverse=True)

        save_to_csv(watchlist_sorted)

if __name__ == "__main__":
    main()